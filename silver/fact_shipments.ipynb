{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37c23ee5-40a2-450a-ac00-4709c97f9fd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0f0aa74-c330-4c0b-9d87-3969c48da4fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bronze_df = spark.read.table('logistics_catalog.bronze.shipments_bronze')\n",
    "\n",
    "display(bronze_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "699a4dcc-0949-4061-a0fb-a0521cd09b70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "bronze_table = \"logistics_catalog.bronze.shipments_bronze\"\n",
    "silver_table = \"logistics_catalog.silver.shipments_silver\"\n",
    "dup_audit_table = \"logistics_catalog.silver.shipments_duplicates_audit\"\n",
    "\n",
    "\n",
    "# 1. Read Bronze\n",
    "\n",
    "bronze_df = spark.read.table(bronze_table)\n",
    "\n",
    "\n",
    "# 2. Cleaning\n",
    "\n",
    "\n",
    "clean_df = (\n",
    "    bronze_df\n",
    "    .withColumn(\"shipment_id\", upper(trim(col(\"shipment_id\")))) \\\n",
    "    .withColumn(\"customer_id\", upper(trim(col(\"customer_id\")))) \\\n",
    "    .withColumn(\"product_id\", upper(trim(col(\"product_id\")))) \\\n",
    "    .withColumn(\"carrier_id\", upper(trim(col(\"carrier_id\")))) \\\n",
    "    .withColumn(\"origin_port\", trim(col(\"origin_port\"))) \\\n",
    "    .withColumn(\"destination_port\", trim(col(\"destination_port\"))) \\\n",
    "    .withColumn(\"shipment_mode\", upper(trim(col(\"shipment_mode\")))) \\\n",
    "    .withColumn(\"shipment_status\", upper(trim(col(\"shipment_status\"))))\n",
    "    .withColumn(\n",
    "    \"shipment_date\",\n",
    "    coalesce(\n",
    "        expr(\"try_to_timestamp(trim(shipment_date), 'yyyy-MM-dd')\"),\n",
    "        expr(\"try_to_timestamp(trim(shipment_date), 'dd/MM/yyyy')\"),\n",
    "        expr(\"try_to_timestamp(trim(shipment_date), 'd-MMM-yyyy')\"),\n",
    "        expr(\"try_to_timestamp(trim(shipment_date), 'MM-dd-yyyy')\"),\n",
    "        expr(\"try_to_timestamp(trim(shipment_date), 'dd-MM-yyyy')\"),\n",
    "        expr(\"try_to_timestamp(trim(shipment_date), 'yyyy/MM/dd')\"),\n",
    "        expr(\"try_to_timestamp(trim(shipment_date), 'yyyyMMdd')\")\n",
    "    )\n",
    ")\n",
    "\n",
    "    .withColumn('freight_cost_usd', col('freight_cost_usd').cast('double'))\n",
    "    .withColumn('ingest_time', current_timestamp())\n",
    "\n",
    "    .drop('_rescued_data')\n",
    "    .withColumn(\n",
    "    \"freight_cost_usd\",\n",
    "    when(col(\"freight_cost_usd\") <= 0, None)\n",
    "    .otherwise(col(\"freight_cost_usd\"))\n",
    ")\n",
    "    .withColumn(\n",
    "    \"shipment_mode\",\n",
    "    when(col(\"shipment_mode\").isin(\"SEA\",\"AIR\"), col(\"shipment_mode\"))\n",
    "    .otherwise(\"UNKNOWN\")\n",
    ")\n",
    "    .withColumn(\n",
    "    \"shipment_status\",\n",
    "    when(col(\"shipment_status\").isin(\"DELIVERED\",\"IN_TRANSIT\"), col(\"shipment_status\"))\n",
    "    .otherwise(\"UNKNOWN\")\n",
    ")\n",
    "    .fillna({\n",
    "        \"customer_id\": \"UNKNOWN\",\n",
    "        \"product_id\": \"UNKNOWN\",\n",
    "        \"carrier_id\": \"UNKNOWN\",\n",
    "        \"freight_cost_usd\": 0\n",
    "    }) \n",
    "    #.filter(col(\"shipment_date\").isNotNull())\n",
    " \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Detect duplicates\n",
    "\n",
    "\n",
    "window_spec = Window.partitionBy(\"shipment_id\").orderBy(col(\"ingest_time\").desc())\n",
    "\n",
    "dedupe_df = clean_df.withColumn(\n",
    "    \"rn\",\n",
    "    row_number().over(window_spec)\n",
    ")\n",
    "\n",
    "valid_df = dedupe_df.filter(\"rn = 1\").drop(\"rn\")\n",
    "duplicate_df = dedupe_df.filter(\"rn > 1\").drop(\"rn\")\n",
    "\n",
    "\n",
    "\n",
    "# 3a. Create duplicates audit table if not exists\n",
    "\n",
    "\n",
    "\n",
    "if not spark.catalog.tableExists(dup_audit_table):\n",
    "    print(\"Creating Duplicates Audit Table for the first time\")\n",
    "    # Create empty table with schema same as duplicate_df\n",
    "    empty_df = duplicate_df.limit(0)\n",
    "    empty_df.write.format(\"delta\").saveAsTable(dup_audit_table)\n",
    "\n",
    "# Save duplicates\n",
    "dup_count = duplicate_df.count()\n",
    "\n",
    "if dup_count > 0:\n",
    "    duplicate_df.write.mode(\"append\").saveAsTable(dup_audit_table)\n",
    "    print(f\"Duplicates logged: {dup_count}\")\n",
    "\n",
    "\n",
    "# Use deduplicated dataframe for silver\n",
    "clean_df = valid_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4. Create Silver table\n",
    "\n",
    "\n",
    "if not spark.catalog.tableExists(silver_table):\n",
    "    print(\"First run - Creating Silver table\")\n",
    "    clean_df.write.format(\"delta\").saveAsTable(silver_table)\n",
    "\n",
    "else:\n",
    "    print(\"Table exists - Running INSERT ONLY MERGE (FACT pattern)\")\n",
    "\n",
    "    silver_delta = DeltaTable.forName(spark, silver_table)\n",
    "\n",
    "    (\n",
    "        silver_delta.alias(\"t\")\n",
    "        .merge(\n",
    "            clean_df.alias(\"s\"),\n",
    "            \"t.shipment_id = s.shipment_id\"\n",
    "        )\n",
    "        .whenMatchedUpdateAll()\n",
    "        .whenNotMatchedInsertAll()   \n",
    "        .execute()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce6737ac-4cf8-4da9-8d02-a2b0645a3b9a",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1770290057275}",
       "filterBlob": "{\"version\":1,\"filterGroups\":[{\"enabled\":true,\"filterGroupId\":\"fg_c47424a6\",\"op\":\"OR\",\"filters\":[{\"filterId\":\"f_f8e73374\",\"enabled\":true,\"columnId\":\"shipment_id\",\"dataType\":\"string\",\"filterType\":\"oneof\"}],\"local\":false,\"updatedAt\":1770290726802}],\"syncTimestamp\":1770290726804}",
       "queryPlanFiltersBlob": "[]",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from logistics_catalog.silver.shipments_silver\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5986018592888647,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "fact_shipments",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
